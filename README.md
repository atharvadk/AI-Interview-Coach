# ğŸ™ï¸ AI-Driven Interview Coaching System

[![React](https://img.shields.io/badge/React-18.x-61DAFB?logo=react)](https://reactjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.110%2B-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![Python](https://img.shields.io/badge/Python-3.9%2B-3776AB?logo=python)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

An intelligent, voice-enabled interview preparation platform that simulates real interview scenarios and provides automated answer evaluation, emotion analysis, and detailed feedback using state-of-the-art AI models.

---

## ğŸ“Œ Project Overview

The **AI-Driven Interview Coaching System** is a web-based application designed to help candidates prepare for technical and non-technical interviews. The system conducts mock interviews through voice interaction, evaluates candidate responses using advanced AI models, analyzes emotional cues, and generates structured feedback to improve interview performance.

The platform aims to replicate real interview pressure while providing objective, AI-driven assessment and personalized improvement suggestions.

---

## ğŸ¯ Objectives

- Simulate real interview scenarios using voice-based interaction  
- Automatically transcribe spoken answers into text  
- Evaluate answers for correctness, relevance, and depth  
- Detect emotional state such as confidence or nervousness  
- Provide structured and actionable feedback  
- Help candidates improve both **content quality** and **communication skills**

---

## ğŸ§  AI Models Used

### 1. **Whisper (Speech-to-Text)**
- **Model:** `whisper-1` (OpenAI)
- **Purpose:** Converts spoken interview answers into text
- **Why:** High accuracy, noise tolerance, and strong performance across accents

### 2. **Gemini Pro (Answer Evaluation)**
- **Model:** Google **Gemini Pro**
- **Purpose:**
  - Evaluates candidate answers
  - Assesses relevance, correctness, clarity, and completeness
  - Generates structured evaluation results
- **Why:** Strong reasoning and evaluation capability for open-ended responses

### 3. **RoBERTa (Emotion Detection)**
- **Model:** `RoBERTa-base` fine-tuned for emotion classification
- **Source:** Hugging Face emotion-finetuned RoBERTa models
- **Purpose:**
  - Detects emotional state from transcribed answers
  - Identifies confidence, nervousness, neutrality, or emotional tone
- **Why:** Context-aware transformer model suitable for subtle emotional cues

---

## ğŸ” System Workflow

```
Candidate Voice Input
        â†“
Whisper-1 (Speech-to-Text)
        â†“
Transcribed Answer
        â†“
    â”œâ”€â”€ Gemini Pro â†’ Answer Evaluation & Scoring
    â”œâ”€â”€ RoBERTa â†’ Emotion Detection
        â†“
Combined Feedback & Performance Summary
```

---

## ğŸš€ Key Features

- ğŸ™ï¸ **Voice-based mock interviews** - Natural conversation flow
- ğŸ“ **Automatic speech-to-text transcription** - Powered by Whisper
- ğŸ“Š **AI-driven answer evaluation** - Using Gemini Pro
- ğŸ˜Š **Emotion detection from responses** - RoBERTa-based analysis
- ğŸ“„ **Structured feedback and scoring** - Actionable insights
- ğŸ“ˆ **Session-wise performance summary** - Track improvement over time
- ğŸŒ **Web-based, platform-independent access** - Works on any modern browser
- ğŸ“‹ **Resume upload & parsing** - Tailored questions based on your profile
- ğŸ‘¤ **User authentication & profiles** - Personalized experience
- ğŸ”” **Real-time notifications** - Stay updated on your progress
- ğŸ“Š **Interactive dashboard** - Visualize your performance metrics
- âš™ï¸ **Customizable settings** - Adjust interview preferences

---

## ğŸ§© Technologies & Frameworks

### Frontend
| Technology | Purpose |
|------------|---------|
| **React.js** | User interface and component management |
| **Vite** | Fast build tool and development server |
| **MediaRecorder API** | Browser-based audio recording |
| **Web Audio API** | Microphone access and audio handling |
| **HTML/CSS/JavaScript** | Core web technologies |
| **Context API** | State management (UserContext) |

### Backend
| Technology | Purpose |
|------------|---------|
| **Python 3.9+** | Backend programming language |
| **FastAPI** | REST API framework |
| **Uvicorn** | ASGI server for FastAPI |

### AI/ML Libraries & APIs
| Library/API | Purpose |
|-------------|---------|
| **OpenAI API** | Whisper speech-to-text |
| **Google Gemini API** | Answer evaluation |
| **Hugging Face Transformers** | RoBERTa model loading |
| **PyTorch** | Deep learning backend |
| **sounddevice** | Audio recording |
| **soundfile** | Audio file I/O |
| **pydub** | Audio processing and conversion |
| **OpenCV** | Video processing (future enhancements) |
| **Pandas/NumPy/SciPy** | Data handling |
| **Matplotlib/Seaborn** | Visualization |
| **Scikit-learn** | ML metrics |

---

## ğŸ–¥ï¸ Application Type

- **Web Application**
- Accessible via modern web browsers
- Requires microphone permission for voice input
- Cross-platform compatible

---

## âš™ï¸ Installation & Setup

### Prerequisites
- **Python 3.9 or higher**
- **Node.js and npm**
- **FFmpeg** (required for audio processing)
- **OpenAI API key** (for Whisper)
- **Google Gemini API key**

#### Installing FFmpeg
- **Windows**: Download from [ffmpeg.org](https://ffmpeg.org/download.html) and add to PATH
- **macOS**: `brew install ffmpeg`
- **Linux**: `sudo apt-get install ffmpeg`

---

### 1ï¸âƒ£ Backend Setup

#### Clone the Repository
```bash
git clone https://github.com/atharvadk/AI-Interview-Coach.git
cd AI-Interview-Coach
```

#### Navigate to Backend Directory
```bash
cd backend
```

#### Install Python Dependencies
```bash
pip install -r requirements.txt
```

Or manually install:
```bash
pip install openai-whisper torch>=2.1.0 transformers>=4.40.0 sounddevice>=0.4.9 soundfile>=0.12.1 numpy>=1.24.0 scipy>=1.11.0 pydub>=0.25.1 python-multipart huggingface_hub>=0.17.1 streamlit>=1.30.0 fastapi>=0.110.0 uvicorn>=0.29.0 opencv-python>=4.8.0 Pillow>=10.0.0 pandas>=2.1.0 matplotlib>=3.8.0 seaborn>=0.12.2 scikit-learn>=1.3.0
```

#### Configure API Keys
Create a `.env` file in the backend directory:
```env
OPENAI_API_KEY=your_openai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
```

#### Run Backend Server
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```
âœ… Backend API running at `http://localhost:8000`

---

### 2ï¸âƒ£ Frontend Setup

#### Open a New Terminal
(Keep the backend server running)

#### Navigate to Frontend Directory
```bash
cd frontend
```

#### Install Dependencies
```bash
npm install
```

#### Configure Backend API Endpoint
Create or update `.env` file in the frontend directory:
```env
REACT_APP_API_URL=http://localhost:8000
```

#### Start React Development Server
```bash
npm start
```
âœ… React app running at `http://localhost:3000`

---

### Running Both Servers

You need **two terminal windows** running simultaneously:

**Terminal 1 (Backend):**
```bash
cd backend
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 (Frontend):**
```bash
cd frontend
npm start
```

---

## ğŸ’» Usage

### Quick Start Guide

**Ensure both servers are running:**
- âœ… Backend: `http://localhost:8000` 
- âœ… Frontend: `http://localhost:3000`

### Starting an Interview

1. **Launch the Application**
   - Navigate to `http://localhost:3000` in your browser
   - Allow microphone access when prompted

2. **Begin Interview Session**
   - Click "Start Interview"
   - Interview questions will appear one by one

3. **Record Your Responses**
   - Click the microphone button to start recording
   - Speak your answer clearly and confidently
   - Click stop when finished

4. **Receive Real-Time Feedback**
   - View automatic transcription of your answer
   - Get AI-generated evaluation from Gemini Pro
   - See emotion analysis results from RoBERTa

5. **Review Performance Summary**
   - Access comprehensive session summary
   - Review individual question performance
   - Identify strengths and areas for improvement
   - Download detailed feedback report

### Example Workflow

```
Question: "Tell me about yourself"
    â†“
[Record Audio] â†’ Whisper Transcription
    â†“
Transcribed Text â†’ Gemini Pro Evaluation + RoBERTa Emotion Detection
    â†“
Feedback: "Well-structured response with relevant examples. 
           Confident tone detected. Score: 8/10
           Suggestions: Add more technical depth..."
```

---

## ğŸ“Š Output & Feedback

The system provides:

- âœ… **Answer Quality Evaluation** - Relevance, correctness, clarity, completeness
- âœ… **Emotional State Analysis** - Confidence level, nervousness indicators
- âœ… **Strengths Identification** - What you did well
- âœ… **Areas for Improvement** - Specific suggestions
- âœ… **Overall Performance Summary** - Session-wise tracking
- âœ… **Scoring Metrics** - Quantitative assessment

---

## ğŸ“‚ Project Structure

```
AI-Interview-Coach/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â””â”€â”€ routes/
â”‚   â”‚       â”œâ”€â”€ __pycache__/
â”‚   â”‚       â”œâ”€â”€ auth.py              # Authentication routes
â”‚   â”‚       â”œâ”€â”€ feedback.py          # Feedback generation routes
â”‚   â”‚       â”œâ”€â”€ files.py             # File upload/download handling
â”‚   â”‚       â””â”€â”€ sessions.py          # Session management routes
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __pycache__/
â”‚   â”‚   â”œâ”€â”€ analysis.py              # Answer analysis service
â”‚   â”‚   â”œâ”€â”€ audio_processing.py      # Audio utilities (sounddevice, pydub)
â”‚   â”‚   â”œâ”€â”€ gemini_client.py         # Gemini Pro API integration
â”‚   â”‚   â”œâ”€â”€ question_bank.py         # Interview questions management
â”‚   â”‚   â”œâ”€â”€ resume_parser.py         # Resume parsing functionality
â”‚   â”‚   â”œâ”€â”€ session_store.py         # Session data management
â”‚   â”‚   â””â”€â”€ sessions.py              # Session handling logic
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                        # Data storage directory
â”‚   â”œâ”€â”€ uploads/                     # Uploaded files (audio, resumes)
â”‚   â”œâ”€â”€ config.py                    # Configuration settings
â”‚   â”œâ”€â”€ main.py                      # FastAPI application entry point
â”‚   â”œâ”€â”€ .gitkeep                     # Git placeholder files
â”‚   â”œâ”€â”€ test.py                      # Backend tests
â”‚   â”œâ”€â”€ test.webm                    # Test audio file
â”‚   â””â”€â”€ requirements.txt             # Python dependencies
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ node_modules/                # npm packages
â”‚   â”œâ”€â”€ public/                      # Static files
â”‚   â”‚   â””â”€â”€ index.html               # HTML template
â”‚   â”‚
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ assets/                  # Images, fonts, etc.
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ FeedbackDashboard.jsx    # Feedback visualization
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.jsx               # Navigation bar
â”‚   â”‚   â”‚   â”œâ”€â”€ Notification.jsx         # Notification system
â”‚   â”‚   â”‚   â”œâ”€â”€ ProgressBar.jsx          # Progress indicator
â”‚   â”‚   â”‚   â”œâ”€â”€ QuestionPanel.jsx        # Question display
â”‚   â”‚   â”‚   â””â”€â”€ ResumeUploadWidget.jsx   # Resume upload component
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ contexts/
â”‚   â”‚   â”‚   â””â”€â”€ UserContext.jsx          # User state management
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.css            # Dashboard styles
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx            # Main dashboard
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.css                 # Home page styles
â”‚   â”‚   â”‚   â”œâ”€â”€ Home.jsx                 # Landing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Interview.jsx            # Interview interface
â”‚   â”‚   â”‚   â”œâ”€â”€ Profile.jsx              # User profile
â”‚   â”‚   â”‚   â”œâ”€â”€ ResumeUpload.jsx         # Resume upload page
â”‚   â”‚   â”‚   â”œâ”€â”€ SessionSummary.jsx       # Session results
â”‚   â”‚   â”‚   â””â”€â”€ Settings.jsx             # User settings
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ App.css                  # Global styles
â”‚   â”‚   â”‚   â”œâ”€â”€ App.jsx                  # Root component
â”‚   â”‚   â”‚   â””â”€â”€ index.css                # Base styles
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ main.jsx                     # React entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ .env                         # Environment variables (API URL)
â”‚   â”œâ”€â”€ .gitkeep                     # Git placeholder
â”‚   â”œâ”€â”€ eslint.config.js             # ESLint configuration
â”‚   â”œâ”€â”€ index.html                   # Main HTML file
â”‚   â”œâ”€â”€ package-lock.json            # npm lock file
â”‚   â”œâ”€â”€ package.json                 # npm dependencies
â”‚   â”œâ”€â”€ README.md                    # Frontend documentation
â”‚   â””â”€â”€ vite.config.js               # Vite configuration
â”‚
â”œâ”€â”€ models/                          # ML models (if stored locally)
â”œâ”€â”€ report/                          # Project reports/documentation
â”œâ”€â”€ uploads/                         # Global uploads directory
â”œâ”€â”€ venv/                            # Python virtual environment
â”‚
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”œâ”€â”€ backend.zip                      # Backend archive
â”œâ”€â”€ frontend.zip                     # Frontend archive
â”œâ”€â”€ package-lock.json                # Root package lock
â”œâ”€â”€ README.md                        # This file
â””â”€â”€ requirements.txt                 # Root Python dependencies
```

---

## ğŸŒŸ What Makes This Project Unique

| Feature | Description |
|---------|-------------|
| **Gemini Pro Integration** | Uses Google's latest LLM specifically for answer evaluation, not generic scoring |
| **RoBERTa Emotion Analysis** | Context-aware emotion detection from transcribed text |
| **Fully Voice-Driven** | Complete interview workflow through voice interaction |
| **Multi-Model AI Pipeline** | Combines three specialized AI models for comprehensive assessment |
| **Technical + Emotional Intelligence** | Evaluates both content quality and communication confidence |
| **End-to-End Automation** | No manual evaluation required |
| **Real Interview Simulation** | Replicates actual interview pressure and scenarios |

---

## ğŸ§ª Use Cases

- ğŸ“ **Placement Preparation** - Practice for campus placements
- ğŸ’¼ **Technical Interview Practice** - Prepare for coding and technical rounds
- ğŸ—£ï¸ **Soft-Skill Improvement** - Enhance communication and confidence
- ğŸ“Š **Self-Assessment** - Evaluate job readiness objectively
- ğŸ« **Academic Demonstration** - Showcase AI + NLP integration
- ğŸ‘¨â€ğŸ« **Educational Tool** - Assist students in interview preparation

---

## ğŸ“Œ Future Enhancements

- [ ] ğŸ“¹ **Facial Expression Analysis** - Using OpenCV for visual cues
- [ ] ğŸŒ **Multi-Language Support** - Interviews in multiple languages
- [ ] ğŸšï¸ **Adaptive Difficulty** - Questions adjust based on performance
- [ ] ğŸ“Š **Analytics Dashboard** - Comprehensive performance tracking
- [ ] ğŸ‘” **Recruiter Mode** - Custom interview configuration
- [ ] ğŸ¯ **Domain-Specific Interviews** - Tailored for different industries
- [ ] ğŸ“„ **PDF Report Export** - Downloadable detailed reports
- [ ] ğŸ”„ **Mock Interview Scheduling** - Timed practice sessions

---

## âš ï¸ Current Limitations

- Requires stable internet connection for AI API calls
- English language only (currently)
- Predefined question sets
- No real-time facial expression analysis yet

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 for Python code
- Use ESLint configuration for JavaScript
- Write meaningful commit messages
- Add tests for new features
- Update documentation as needed

---

## ğŸ”‘ API Keys Required

You need the following API keys:

- **OpenAI API Key** (for Whisper) - [Get it here](https://platform.openai.com/api-keys)
- **Google Gemini API Key** - [Get it here](https://ai.google.dev/)

Set them as environment variables in your `.env` file:

```env
OPENAI_API_KEY=your_openai_key_here
GEMINI_API_KEY=your_gemini_key_here
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

**Atharva Kavade**  
Artificial Intelligence and Data Science  
Vishwakarma Institute of Technology, Pune

- GitHub: [@atharvadk](https://github.com/atharvadk)

**Srushti Kasurde**  
Artificial Intelligence and Data Science  
Vishwakarma Institute of Technology, Pune

- GitHub: [@srushti1010-kasurde](https://github.com/srushti1010-kasurde)

- Repository: [AI-Interview-Coach](https://github.com/atharvadk/AI-Interview-Coach)

---

## ğŸ™ Acknowledgments

- **OpenAI** for the Whisper speech recognition model
- **Google** for the Gemini Pro API
- **Hugging Face** for the emotion-finetuned RoBERTa model
- **FastAPI** and **React** communities for excellent frameworks
- All contributors and testers

---

## ğŸ Conclusion

The AI-Driven Interview Coaching System demonstrates the practical application of speech processing, large language models, and emotion-aware NLP in building intelligent educational tools. By combining Whisper, Gemini Pro, and RoBERTa, the system delivers a realistic, automated, and insightful interview preparation experience.

---

## ğŸ“§ Contact

For questions, suggestions, or collaboration:
- ğŸ› Issues: [GitHub Issues](https://github.com/atharvadk/AI-Interview-Coach/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/atharvadk/AI-Interview-Coach/discussions)

---

<div align="center">

**â­ Star this repository if it helped you ace your interviews!**

Built with â¤ï¸ to help everyone succeed in their career journey

</div>
